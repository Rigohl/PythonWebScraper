<!-- AUTO-GENERATED HIGH DETAIL README (Mantener actualizado) -->

# Web Scraper PRO ‚Äì Plataforma Inteligente de Exploraci√≥n Web

Sistema de crawling, extracci√≥n y aprendizaje incremental orientado a resiliencia, adaptabilidad y extensibilidad. Dise√±ado para:

- Operar en modo totalmente automatizado (crawler + IA h√≠brida)
- Ejecutar sesiones interactivas (TUI)
- Aplicar extracci√≥n estructurada din√°micamente (LLM Zero‚ÄëShot)
- Aprender patrones de cada dominio y optimizar la estrategia- Modo "focus" a un dominio.

---

## 16.1. Chat IA Biling√ºe con Procesamiento de Lenguaje Natural

El dashboard profesional incluye un chat inteligente biling√ºe (F9 para activar) con capacidades de:

### üó£Ô∏è Procesamiento de Lenguaje Natural

El chat puede entender y procesar peticiones en lenguaje natural tanto en espa√±ol como en ingl√©s. No necesitas memorizar comandos espec√≠ficos:

**Ejemplos de uso:**

- "Busca informaci√≥n sobre Python" ‚Üí B√∫squeda autom√°tica en base de conocimiento
- "Inicia un scraping en amazon.com" ‚Üí Configura y ejecuta scraping
- "Edita el archivo config.json" ‚Üí Abre editor de archivos
- "Ejecuta 'dir' en terminal" ‚Üí Ejecuta comando en PowerShell

### üéØ Intenciones Reconocidas

| Intenci√≥n | Ejemplos en Espa√±ol | Ejemplos en Ingl√©s |
|-----------|-------------------|-------------------|
| **B√∫squeda** | "Busca datos sobre X", "Encuentra informaci√≥n de Y" | "Search for X", "Find information about Y" |
| **Scraping** | "Haz scraping de sitio.com", "Extrae datos de p√°gina.html" | "Scrape website.com", "Extract from page.html" |
| **Conocimiento** | "Qu√© sabes sobre X?", "H√°blame de Y" | "What do you know about X?", "Tell me about Y" |
| **Edici√≥n** | "Edita archivo.py", "Modifica el c√≥digo" | "Edit file.py", "Modify the script" |
| **Terminal** | "Ejecuta comando X", "Corre 'dir' en cmd" | "Run command X", "Execute 'ls' in terminal" |

### üîß Comandos Directos (Prefijo `/`)

Para usuarios avanzados, tambi√©n soporta comandos directos:

- `/crawl URL` - Inicia scraping
- `/kb CONSULTA` - Consulta base de conocimiento
- `/edit ARCHIVO` - Edita archivos
- `/terminal COMANDO` - Ejecuta comandos
- `/help` - Ayuda completa

### üõ°Ô∏è Seguridad

El sistema incluye medidas de seguridad para:

- Bloquear comandos peligrosos en terminal
- Restringir edici√≥n a tipos de archivo seguros
- Validar comandos antes de ejecutar

---

## 17. Scripts de Mantenimientoportar datos limpios y auditables

---

## 1. Requisitos Previos

| Recurso | M√≠nimo Recomendado | Notas |
|---------|--------------------|-------|
| Python  | 3.10+ (probado 3.12) | Asegura UTF‚Äë8 por defecto |
| Playwright | √öltima estable | Necesario salvo modo `--demo` |
| SO | Windows / Linux / macOS | Batch principal pensado para Windows |
| RAM | ‚â• 2 GB | M√°s si activas RL + muchas pesta√±as |
| Conexi√≥n | Estable | Para scraping real (demo funciona offline) |

Instala navegadores de Playwright tras dependencias:

```powershell
python -m playwright install
```

---

## 2. Lanzamiento R√°pido (Windows ‚Äì Recomendado)

### üöÄ Nuevo: Dashboard Profesional

Ejecuta el **nuevo script mejorado** que incluye la interfaz profesional:

```powershell
WebScraperPRO_Enhanced.bat
```

El **Dashboard Profesional** ofrece:

- üéØ **Interfaz moderna tipo dashboard** con m√©tricas en tiempo real
- üß† **Control completo de IA H√≠brida** (IA-A + IA-B)
- üìä **Monitoreo avanzado** por dominio y rendimiento
- ‚öôÔ∏è **Configuraci√≥n integrada** de todas las funciones
- üì§ **Exportaci√≥n m√∫ltiple** (CSV, JSON, Markdown, Excel, Word)
- üîß **Auto-reparaci√≥n** y an√°lisis inteligente

### üì± Script Original (Compatibilidad)

Para el lanzador cl√°sico:

```powershell
WebScraperPRO.bat
```

Ambos scripts ofrecen acceso a las siguientes operaciones:

1. **üöÄ Dashboard Profesional (NUEVO):** Interfaz moderna con control total y chat IA biling√ºe
2. **üì± Interfaz TUI Cl√°sica:** La interfaz original para usuarios familiarizados
3. **üï∑Ô∏è Crawling Directo:** Scraping inmediato desde l√≠nea de comandos
4. **üéÆ Modo Demo:** Demostraci√≥n sin dependencias de navegador
5. **üìä Brain Snapshot:** Estado completo del sistema de IA
6. **üì§ Exportar Datos:** M√∫ltiples formatos disponibles
7. **üîß Configuraci√≥n:** Ajustes avanzados del sistema
8. **‚ùì Ayuda:** Documentaci√≥n integrada
9. **Salir:** Cierra el panel de control.

En Linux/macOS usar `./WebScraperPRO.sh` (si existe) o invocar manualmente comandos equivalentes.

---

## 3. Instalaci√≥n Manual (Alternativa)

```powershell
python -m pip install -r requirements.txt
python -m playwright install
```

Probar modo demo (no requiere browsers instalados si contenido local):

```powershell
python -m src.main --demo
```

Iniciar TUI:

```powershell
python -m src.main --tui
```

Crawler directo (URLs iniciales):

```powershell
python -m src.main --crawl https://books.toscrape.com/
```

Exportar resultados:

```powershell
python -m src.main --export-csv export.csv
python -m src.main --export-json export.json
```

Snapshot del cerebro h√≠brido (si habilitado):

```powershell
python -m src.main --brain-snapshot
```

Consultar la base de conocimiento del cerebro:

```powershell
python -m src.main --query-kb "tu pregunta"
```

Generar reporte de auto-reparaci√≥n:

```powershell
python -m src.main --repair-report
```

Ver ayuda:

```powershell
python -m src.main --help
```

---

## 4. Arquitectura General

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   CLI/TUI   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Usuario    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   main.py     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                              Orquestaci√≥n
                                    ‚îÇ
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                             ‚îÇ Orchestrator  ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         Inteligencia              ‚îÇ     ‚îÇ  Persistencia
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ     ‚îÇ
   ‚îÇ HybridBrain  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ     ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ   ‚îÇ     ‚îî‚îÄ‚îÄ‚ñ∂‚îÇ  Database     ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ   ‚îÇ         ‚îÇ (SQLite)      ‚îÇ
   ‚îÇ LLM Extractor‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ   ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   RL      ‚îÇ   ‚îÇ Workers
   ‚îÇ RL Agent     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   ‚îÇ  (Playwright + Scraper)
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ   ‚îÇ
                              ‚ñº   ‚ñº
                          AdvancedScraper
```

### Estructura del Proyecto

```text
PythonWebScraper/
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente principal
‚îú‚îÄ‚îÄ tests/                  # Suite de pruebas
‚îú‚îÄ‚îÄ docs/                   # Documentaci√≥n t√©cnica y desarrollo
‚îú‚îÄ‚îÄ scripts/                # Scripts de utilidad y herramientas
‚îú‚îÄ‚îÄ data/                   # Datos, bases de datos y archivos de ejemplo
‚îú‚îÄ‚îÄ exports/                # Archivos exportados (CSV, JSON, MD)
‚îú‚îÄ‚îÄ logs/                   # Archivos de log y sincronizaci√≥n
‚îú‚îÄ‚îÄ config/                 # Configuraciones del proyecto
‚îú‚îÄ‚îÄ backups/                # Respaldos y parches
‚îú‚îÄ‚îÄ tools/                  # Herramientas de mantenimiento
‚îú‚îÄ‚îÄ WebScraperPRO.bat      # Punto de entrada principal (Windows)
‚îú‚îÄ‚îÄ WebScraperPRO.sh       # Punto de entrada principal (Linux/macOS)
‚îú‚îÄ‚îÄ README.md              # Esta documentaci√≥n
‚îî‚îÄ‚îÄ requirements.txt       # Dependencias de producci√≥n
```

Componentes Clave:

- `Orchestrator`: Concurre, prioriza, reintenta, coordina IA y RL.
- `AdvancedScraper`: Abstracci√≥n por p√°gina (adaptador navegador + LLM + parsing + hashing + links).
- `HybridBrain`: Fusi√≥n de m√©tricas hist√≥ricas + aprendizaje aut√≥nomo.
- `LLMExtractor`: Limpieza/normalizaci√≥n y extracci√≥n estructurada zero-shot.
- `RLAgent` (opcional): Ajusta din√°mica de backoff / heur√≠sticas.
- `DatabaseManager`: Persistencia (resultados, cookies, esquemas, APIs descubiertas).

---

## 5. Flujo Operativo Detallado

1. URLs iniciales se insertan en cola de prioridad.
2. Precalificaci√≥n opcional v√≠a HEAD (tipo, tama√±o, redirecciones).
3. Workers toman URL ‚Üí abren p√°gina (Playwright) con fingerprint + stealth.
4. Se gestionan cookies (carga / persistencia por dominio) y user-agent.
5. Listener de respuestas captura APIs JSON (xhr/fetch) y las hashea para deduplicaci√≥n.
6. Se obtiene HTML, se aplica Readability + limpieza LLM.
7. Validaci√≥n de calidad (longitud m√≠nima, frases prohibidas, duplicados).
8. Extracci√≥n estructurada (si existe esquema din√°mico pydantic por dominio).
9. Screenshot (si disponible) y perceptual hash (phash) para detectar cambios visuales.
10. Registro en DB y actualizaci√≥n de m√©tricas de dominio.
11. Actualizaci√≥n de cerebro / inteligencia (estat√≠sticas multi-dominio + patrones).
12. Encolado de nuevos enlaces internos visibles filtrados (evita repetitivos / trampas).
13. RL (si activo) recibe estado ‚Üí acci√≥n ‚Üí posterior aprendizaje con recompensa.
14. Sincronizaciones peri√≥dicas en `IA_SYNC.md` (controladas por `IA_SYNC_EVERY`).

---

## 6. Inteligencia: C√≥mo Hacerlo M√°s ‚ÄúInteligente‚Äù

| Capacidad | C√≥mo Activar | Mejora que Aporta |
|-----------|--------------|--------------------|
| HybridBrain | Variable de entorno `HYBRID_BRAIN=1` al lanzar (batch ya lo puede exportar) | Fusi√≥n de estad√≠sticas + aprendizaje incremental |
| Ajustar Frecuencia Sync | `IA_SYNC_EVERY=50` (ejemplo) | Menos E/S en disco o mayor granularidad hist√≥rica |
| LLM Limpieza avanzada | Proveer `LLM_API_KEY` y `LLM_MODEL` | Texto m√°s puro y extracci√≥n robusta |
| Extracci√≥n estructurada | Guardar esquema din√°mico en DB (ver secci√≥n 11) | Datos tabulares listos sin regex/selectors |
| RL Agent | Lanzar con `--use-rl` | Optimizaci√≥n adaptativa de estrategias |
| Filtrado heur√≠stico | Ajustar thresholds en `settings.py` | Menos ruido (p√°ginas vac√≠as/baja calidad) |
| Prioridad de dominios | Brain aprende tasas de √©xito | Mejora cobertura √∫til primero |

### 6.1 Activar HybridBrain

```powershell
$env:HYBRID_BRAIN="1"
WebScraperPRO.bat
```

o directo:

```powershell
HYBRID_BRAIN=1 python -m src.main --crawl https://books.toscrape.com/
```

### 6.2 Alimentar el Cerebro M√°s R√°pido

- Aumenta `CONCURRENCY` si tu m√°quina lo soporta.
- Proporciona diversas URLs iniciales para exponer m√°s patrones.
- Usa `--demo` solo para smoke tests: no entrena realmente.

### 6.3 M√©tricas de Inteligencia

Llama a `--brain-snapshot` para JSON con:

```jsonc
{
  "simple_brain": {...},
  "autonomous_brain": {
    "domains_learned": 12,
    "avg_success_rate": 0.54,
    "patterns_identified": 5
  }
}
```

---

## 7. Configuraci√≥n Centralizada

Orden de carga (prioridad alta‚Üíbaja):

1. Variables de entorno
2. `.env`
3. Defaults en `settings.py`

### 7.1 Variables Comunes

| Variable | Descripci√≥n | Ejemplo |
|----------|-------------|---------|
| `CONCURRENCY` | Workers simult√°neos | `8` |
| `LLM_API_KEY` | Clave proveedor LLM | `sk-...` |
| `LLM_MODEL` | Modelo remoto | `gpt-4o-mini` |
| `ROBOTS_ENABLED` | Respetar robots.txt | `true` |
| `HYBRID_BRAIN` | Habilita cerebro h√≠brido | `1` |
| `IA_SYNC_EVERY` | Intervalo sync IA | `25` |
| `OFFLINE_MODE` | Fuerza modo sin LLM remoto | `1` |
| `DB_PATH` | Ruta DB sqlite | `data/scraper_database.db` |
| `MIN_CONTENT_LENGTH` | Longitud m√≠nima texto √∫til | `400` |

### 7.2 Ejemplo `.env`

```env
CONCURRENCY=6
HYBRID_BRAIN=1
IA_SYNC_EVERY=40
DB_PATH=data/scraper_database.db
OFFLINE_MODE=1
```

---

## 8. Adaptadores y Extensibilidad

### 8.1 BrowserAdapter

Interfaz: `navigate_to_url`, `get_content`, `screenshot`, cookies, listeners de respuesta. Implementaciones:

- `PlaywrightAdapter`
- `MockBrowserAdapter` (tests / offline)

### 8.2 LLMAdapter

Interfaz: `clean_text`, `extract_structured_data`, `summarize_content`. Implementaciones:

- `OpenAIAdapter`
- `OfflineLLMAdapter`
- `MockLLMAdapter`

Puedes a√±adir proveedores nuevos creando un adaptador que implemente la interfaz y pasando `LLMExtractor(adapter=nuevo)`.

---

## 9. ScrapeResult (Modelo de Datos)

Campos principales (resumen):

- `url`, `title`, `content_text`, `content_html`
- `links` (internos visibles procesados)
- `visual_hash` (o `"unavailable"`)
- `content_hash`
- `content_type` (heur√≠stico: PRODUCT / BLOG_POST / ARTICLE / GENERAL / UNKNOWN)
- `extracted_data` (dict estructurado si esquema aplicado)
- `http_status_code`
- `crawl_duration`, `response_time` (timings)
- `llm_summary` (si fue generado)

---

## 10. Base de Datos y Persistencia

SQLite (archivo por defecto: `data/scraper_database.db`). Contiene (nomenclatura aproximada):

- `results` ‚Äì p√°ginas procesadas
- `cookies` ‚Äì cookies por dominio
- `api_discoveries` ‚Äì endpoints JSON capturados (hash + URL)
- `extraction_schemas` ‚Äì definiciones din√°micas (JSON ‚Üí modelado pydantic)

Exportaciones:

```powershell
python -m src.main --export-csv datos.csv
python -m src.main --export-json datos.json
```

---

## 11. Esquemas de Extracci√≥n Din√°mica (LLM Zero‚ÄëShot)

1. Definir diccionario simple de campos: `{ "price": "str", "rating": "float" }`.
2. Guardarlo v√≠a `DatabaseManager.save_llm_extraction_schema(domain, json.dumps(schema_dict))`.
3. Pr√≥ximos scrapes de ese dominio crean un modelo din√°mico y el LLM extrae datos.

Ventajas: No dependes de selectores CSS fr√°giles. Cambios de HTML menores no rompen la extracci√≥n.

---

## 12. Reintentos y Backoff

- Reintentos hasta `MAX_RETRIES` (config).
- Backoff exponencial ajustado por RL (si habilitado) o ajustes heur√≠sticos.
- Estados posibles: `SUCCESS`, `FAILED`, `RETRY`, `LOW_QUALITY`, `EMPTY`.

---

## 13. RL (Aprendizaje por Refuerzo)

Activar:

```powershell
python -m src.main --crawl https://books.toscrape.com/ --use-rl
```

Estado usado: ratios de fallo / baja calidad + factor de backoff actual.
Recompensas:

- +1 √©xito
- -0.5 baja calidad / vac√≠o
- -1 fallo

Resultado: Ajuste din√°mico de `current_backoff_factor`.

---

## 14. Mecanismos Anti-Trampa y Calidad

- Detecci√≥n de rutas repetitivas (evita loops).
- Validaci√≥n de longitud m√≠nima.
- Filtros de frases error (404, maintenance, etc.).
- Hashing de contenido para duplicados.
- phash para detectar cambios visuales futuro (comparaci√≥n puede ampliarse).

---

## 15. Inteligencia H√≠brida (HybridBrain)

Combina:

- M√©tricas simples (tasa √©xito, dominios, eventos)
- Patrones de contenido (frecuencia, tipo)
- Insights incrementalmente derivados

Snapshot obtiene:

```powershell
python -m src.main --brain-snapshot > brain.json
```

Recomendado activarlo siempre en producci√≥n (`HYBRID_BRAIN=1`).

---

## 16. TUI (Interfaz Textual)

La interfaz textual (basada en Textual) proporciona observabilidad en tiempo real y control operativo sin abrir m√∫ltiples terminales. Est√° pensada para reflejar la ‚Äúinteligencia‚Äù del scraper de forma clara y accionable.

Caracter√≠sticas clave:

- Banner de Inteligencia (arriba): estado Robots, √âtica, Offline, RL, tasa de √©xito acumulada; indicadores de anomal√≠a (fallos ‚â•40%, backoff >2x, PAUSADO).
- Pesta√±as de Control / M√©tricas: vista Crawl (inicio: URL, concurrencia, flags) y vista Estad√≠sticas (global, dominio, Brain, Inteligencia acumulada).
- M√©tricas Globales (LiveStats): procesadas, √©xitos, fallos, reintentos, cola y % con color (verde/amarillo/rojo).
- M√©tricas por Dominio: backoff din√°mico, scrapeados, baja calidad, vac√≠os, fallos (colores seg√∫n ratios).
- Brain Adaptativo: visitas, tasas √©xito/error, link yield, prioridad derivada, eventos recientes.
- Inteligencia Aut√≥noma: dominios aprendidos, sesiones, √©xito promedio, patrones, estrategias optimizadas, √∫ltimo aprendizaje.
- Alertas Cr√≠ticas: mensajes coloreados para incidencias de extracci√≥n, saturaci√≥n y anomal√≠as.
- Progreso & Etapas: barra de progreso y etapa (Idle / Queueing / Crawling / Finalizing / Completed).
- Barra de Estado: totales, tasa de √©xito, throughput (TPS) y tiempo transcurrido (mm:ss).
- Notificaciones Toast: feedback de inicio, pausa, export, errores sin bloquear.
- Exportaci√≥n Markdown Manual: bot√≥n ‚ÄúExportar MD‚Äù o `x` genera `exports/manual_export.md`.
- Preferencias Persistentes: autoscroll y visibilidad del log guardadas en `config/ui_prefs.json`.
- Pausa de UI: bufferiza m√©tricas sin perder datos; refresco al reanudar.
- Ocultar Panel de Log: maximiza espacio para an√°lisis profundo de m√©tricas.

Atajos de teclado (Keybindings):

| Tecla | Acci√≥n | Descripci√≥n |
|-------|--------|-------------|
| s | start | Inicia crawling |
| t | stop | Detiene crawling (cancela worker) |
| p | pause_resume | Pausa/Reanuda refresco UI (buffer) |
| **F9** | **toggle_chat** | **üÜï Muestra/oculta chat IA biling√ºe** |
| q | quit | Salir de la TUI |
| r | toggle_robots | Activa/desactiva respeto robots.txt |
| e | toggle_ethics | Activa/desactiva comprobaciones de √©tica |
| o | toggle_offline | Cambia modo Offline (sin LLM remoto) |
| d | toggle_dark | Tema oscuro (Textual) adicional |
| l | toggle_log_panel | Oculta/Muestra panel de log |
| x | export_markdown | Exporta reporte Markdown manual |
| a | toggle_autoscroll | Autoscroll del log ON/OFF |
| c | clear_log | Limpia el log principal |
| / | focus_url | Foco r√°pido en campo URL |
| ? | help | Overlay de ayuda |
| Enter (en URL) | start | Atajo r√°pido para lanzar |
| Esc (overlay) | cerrar | Cierra overlays (ayuda) |

Color Sem√°ntico:

- Verde: estado saludable / √©xito ‚â• 80% / backoff bajo.
- Amarillo: condiciones intermedias / atenci√≥n recomendada.
- Rojo: anomal√≠a, alta tasa de fallo, m√©trica degradada.

Anomal√≠as Detectadas actualmente:

- Tasa de fallo global ‚â• 40% ‚Üí Banner muestra ‚ÄúALTA Falla‚Äù.
- Backoff m√°ximo de dominio > 2x ‚Üí Banner muestra indicador ‚è≥.
- Estado de pausa activo ‚Üí ‚ÄúPAUSADO‚Äù resaltado.

Exportaci√≥n Autom√°tica vs Manual:

- Autom√°tica: controlada por `AUTO_EXPORT_MD=1` (post-run en modo runner tradicional).
- Manual: desde TUI con bot√≥n o atajo `x`. Ideal para snapshots intermedios.

Ejecuci√≥n:

```powershell
python -m src.main --tui
```

Sugerencias de Operaci√≥n:

- Iniciar con un solo dominio para validar extracci√≥n y luego ampliar.
- Observar `Backoff` y `Fallos` por dominio para ajustar l√≠mites antes de escalar.
- Usar pausa (`p`) cuando se desee inspeccionar tablas sin parpadeo constante.
- Exportar un Markdown intermedio para auditor√≠as o reportes de progreso.

Roadmap UI (futuro potencial):

- Filtros interactivos por dominio / tasa de error.
- Export JSON directo desde la TUI.
- Visualizaci√≥n de grafo de enlaces (ASCII o sparkline).
- Modo ‚Äúfocus‚Äù a un dominio.

---

## 17. Scripts de Mantenimiento

`tools/update_policy.py`:

```powershell
python tools/update_policy.py --domain example.com --robots-output robots_example.txt
```

Opciones:

- `--update-agents`
- `--update-policy`

Salida con WARNING controlada si robots no disponible (tests validan esto).

---

## 18. Backups y Restauraci√≥n

Directorio `backups/` contiene snapshots / parches / gu√≠as:

- `RESTORE_GUIDE.md`
- `cleanup_backups.ps1`

Buenas pr√°cticas:

- Mantener snapshots limpios (el script de cleanup ayuda).
- No versionar datos voluminosos innecesarios.

---

## 19. Pruebas y Calidad

Ejecutar tests:

```powershell
pytest -q
```

Tipos:

- Unitarios: adaptadores, extracci√≥n, m√©tricas.
- Integraci√≥n: orquestador + scraping simulado.
- Skips actuales documentan l√≥gica a√∫n por implementar (retry advanced / robots strict).

Antes de commit (sugerido):

```powershell
pytest -q
python -m pip install -r requirements-dev.txt
flake8 src
```

---

## 20. Estrategias para ‚ÄúHacerlo M√°s Inteligente‚Äù (Checklist Accionable)

| Objetivo | Acci√≥n | Resultado |
|----------|--------|-----------|
| Mejor limpieza | A√±adir `LLM_API_KEY` | Texto sem√°ntico m√°s estable |
| M√°s patrones | Aumentar diversidad de dominios | Mejor priorizaci√≥n futura |
| Menos fallos | Analizar `domain_metrics` y bloquear dominios ruidosos | Ahorro de recursos |
| Capturar APIs | Revisar tabla APIs y derivar endpoints √∫tiles | Extensi√≥n de scraping de datos JSON |
| Extracci√≥n tabular | Definir esquemas din√°micos | CSV listo para BI |
| Acelerar entrenamiento RL | Lanzar varias sesiones cortas | Ajuste m√°s r√°pido de backoff |
| Persistencia hist√≥rica | Automatizar snapshots `brain-snapshot` (cron) | L√≠nea de tiempo de aprendizaje |
| Evoluci√≥n | Ajustar thresholds en `settings.py` tras observar m√©tricas | Reducci√≥n de falsos positivos |

---

## 21. Seguridad, √âtica y Cumplimiento

- Respetar t√©rminos de uso de los sitios.
- Evitar scraping de datos personales sensibles.
- Activar siempre `ROBOTS_ENABLED=true` salvo pruebas internas.
- Registrar en logs decisiones sensibles (ya soportado parcialmente).
- Limitar concurrencia contra dominios peque√±os para no sobrecargar.

---

## 22. Resoluci√≥n de Problemas (Troubleshooting)

| Problema | Causa Com√∫n | Soluci√≥n |
|----------|-------------|----------|
| `playwright._impl... not found` | No instalaste browsers | `python -m playwright install` |
| Contenido muy corto | P√°gina din√°mica/lazy | Aumenta espera; implementar scroll (futuro) |
| Muchos `FAILED` | Bloqueo anti-bot | Disminuye velocidad / activa stealth / rota UAs |
| Duplicados frecuentes | P√°ginas casi id√©nticas | Ajusta hashing o filtra par√°metros query |
| LLM no limpia bien | Modo offline | Proveer API key + modelo adecuado |
| RL no aprende | Sesi√≥n corta | Ejecuta m√°s iteraciones / m√°s dominios |

---

## 23. Roadmap (Extracto de `MEJORAS.md`)

Ideas futuras:

- Scroll infinito y carga perezosa.
- Detecci√≥n visual diferencial (comparar phash base vs actual).
- Auto-generaci√≥n de esquemas a partir de clustering sem√°ntico.
- Persistencia en motor anal√≠tico (DuckDB / Parquet) opcional.

---

## 24. Comandos Comunes (Resumen)

```powershell
# Demo r√°pida
python -m src.main --demo
# Crawler b√°sico
python -m src.main --crawl https://books.toscrape.com/
# Crawler con RL + HybridBrain
HYBRID_BRAIN=1 python -m src.main --crawl https://books.toscrape.com/ --use-rl
# TUI
python -m src.main --tui
# Exportar
python -m src.main --export-csv out.csv
python -m src.main --export-json out.json
# Snapshot inteligencia
python -m src.main --brain-snapshot
```

---

## 25. Est√°ndares de C√≥digo / Contribuci√≥n

- Tipado consistente (anotaciones obligatorias en nuevas funciones p√∫blicas).
- Evitar l√≥gica compleja en l√≠nea ‚Üí extraer helpers privados.
- Manejo de excepciones granular (sin capturas globales salvo en bordes).
- No introducir dependencias nuevas sin justificar impacto.
- Mantener adaptadores desacoplados del resto del n√∫cleo.

---

## 26. Integraci√≥n con CI/CD (Sugerido)

Pasos recomendados pipeline:

1. Instalar deps
2. Ejecutar tests
3. Generar export de ejemplo (sanity)
4. Producir snapshot brain para auditor√≠a

---

## 27. M√©tricas Clave a Observar

| M√©trica | Fuente | Uso |
|---------|--------|-----|
| `avg_success_rate` | HybridBrain | Salud global |
| `low_quality_ratio` | domain_metrics | Ajustar backoff |
| `patterns_identified` | Autonomous brain | Cobertura sem√°ntica |
| `queue_size` | Orchestrator stats | Saturaci√≥n / tuning concurrency |
| `response_time` | ScrapeResult | L√≠mite vs timeouts |

---

## 28. Extensiones Futuras (Puntos de Inyecci√≥n)

| √Årea | Estrategia |
|------|-----------|
| Normalizaci√≥n HTML | Hook antes de Readability |
| Detecci√≥n duplicados | Cambiar hash ‚Üí simhash / fuzzy |
| Persistencia | Implementar repositorio alterno (DuckDB) |
| Prioridad URLs | Sustituir `_calculate_priority` por modelo ML avanzado |
| Clasificaci√≥n contenido | A√±adir clasificador tem√°tico ML |

---

## 29. Licenciamiento y Uso

Revisa pol√≠ticas internas antes de producci√≥n. No almacenar claves sensibles en repositorio. A√±adir archivo LICENSE si se libera p√∫blicamente.

---

## 30. Resumen Final

Este sistema ya soporta scraping concurrente, limpieza inteligente, extracci√≥n din√°mica, cerebro h√≠brido, RL opcional, exportaciones y una arquitectura modular basada en adaptadores. Para ‚Äúhacerlo m√°s inteligente‚Äù: habilita HybridBrain, provee un LLM real, define esquemas din√°micos y ejecuta sesiones amplias y variadas.

---

¬øNecesitas un manual operativo separado o gu√≠as de escalado? Abre un issue / extensi√≥n de documentaci√≥n.

<!-- FIN README DETALLADO -->
