"""
Command Processor for Conversational AI

This module processes commands generated by the conversational AI and executes
them using the appropriate scraper components.
"""

import asyncio
import logging
import re
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING
from urllib.parse import urlparse

from ..database import DatabaseManager
from ..intelligence.llm_extractor import LLMExtractor
from ..managers.user_agent_manager import UserAgentManager
from ..settings import settings

# Use TYPE_CHECKING to avoid circular imports
if TYPE_CHECKING:
    from ..orchestrator import ScrapingOrchestrator
    from .bot_manager import BotManager

logger = logging.getLogger(__name__)


class CommandProcessor:
    """
    Processes and executes commands generated by the conversational AI system
    """
    
    def __init__(
        self, 
        db_manager: Optional[DatabaseManager] = None,
        bot_manager: Optional["BotManager"] = None
    ):
        self.db_manager = db_manager or DatabaseManager()
        
        # Import bot_manager here to avoid circular import
        if bot_manager is None:
            from .bot_manager import BotManager
            self.bot_manager = BotManager()
        else:
            self.bot_manager = bot_manager
            
        self.user_agent_manager = UserAgentManager()
        self.llm_extractor = LLMExtractor() if settings.LLM_API_KEY else None
        
        # Track active operations
        self.active_operations: Dict[str, asyncio.Task] = {}
        
        # Command handlers
        self.command_handlers = {
            'search_web': self._handle_search_web,
            'crawl_urls': self._handle_crawl_urls,
            'create_bot': self._handle_create_bot,
            'analyze_data': self._handle_analyze_data,
            'get_system_status': self._handle_get_system_status,
            'start_bot': self._handle_start_bot,
            'stop_bot': self._handle_stop_bot,
            'list_bots': self._handle_list_bots,
            'export_data': self._handle_export_data
        }

    async def execute_commands(
        self, 
        commands: List[Dict[str, Any]], 
        session_id: str
    ) -> List[Dict[str, Any]]:
        """
        Execute a list of commands and return results
        
        Args:
            commands: List of command dictionaries
            session_id: Session ID for tracking
            
        Returns:
            List of execution results
        """
        results = []
        
        for i, command in enumerate(commands):
            command_id = f"{session_id}_{i}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            try:
                result = await self._execute_single_command(command, command_id)
                results.append({
                    'command_id': command_id,
                    'command': command,
                    'status': 'success',
                    'result': result,
                    'timestamp': datetime.now().isoformat()
                })
                
            except Exception as e:
                logger.error(f"Error executing command {command_id}: {e}", exc_info=True)
                results.append({
                    'command_id': command_id,
                    'command': command,
                    'status': 'error',
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
        
        return results

    async def _execute_single_command(
        self, 
        command: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Execute a single command"""
        command_type = command.get('type')
        parameters = command.get('parameters', {})
        
        if command_type not in self.command_handlers:
            raise ValueError(f"Unknown command type: {command_type}")
        
        handler = self.command_handlers[command_type]
        return await handler(parameters, command_id)

    async def _handle_search_web(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle web search commands"""
        query = parameters.get('query', '')
        max_results = parameters.get('max_results', 10)
        deep_crawl = parameters.get('deep_crawl', False)
        
        if not query:
            raise ValueError("Search query is required")
        
        # Generate search URLs
        search_urls = self._generate_search_urls(query, max_results)
        
        # Create temporary bot for search
        bot_id = self.bot_manager.create_smart_bot_from_description(
            f"Buscar información sobre: {query}"
        )
        
        # Configure bot with search URLs
        bot = self.bot_manager.active_bots[bot_id]
        bot.config.target_urls = search_urls
        bot.config.max_pages = max_results
        bot.config.max_depth = 2 if deep_crawl else 1
        
        # Start the search bot
        success = await self.bot_manager.start_bot(bot_id)
        
        return {
            'bot_id': bot_id,
            'search_query': query,
            'search_urls': search_urls,
            'started': success,
            'status': 'Bot de búsqueda iniciado' if success else 'Error al iniciar bot'
        }

    def _generate_search_urls(self, query: str, max_results: int) -> List[str]:
        """Generate search URLs for a query"""
        # Encode query for URLs
        encoded_query = query.replace(' ', '+')
        
        search_urls = [
            f"https://www.google.com/search?q={encoded_query}&num={min(max_results, 10)}",
            f"https://duckduckgo.com/?q={encoded_query}",
            f"https://www.bing.com/search?q={encoded_query}&count={min(max_results, 10)}",
        ]
        
        # Add domain-specific searches for technical topics
        if any(tech_term in query.lower() for tech_term in ['python', 'javascript', 'api', 'programming', 'code']):
            search_urls.extend([
                f"https://stackoverflow.com/search?q={encoded_query}",
                f"https://github.com/search?q={encoded_query}&type=repositories",
            ])
        
        # Add news searches for current events
        if any(news_term in query.lower() for news_term in ['news', 'noticias', 'breaking', 'latest']):
            search_urls.extend([
                f"https://news.google.com/search?q={encoded_query}",
            ])
        
        return search_urls[:max_results // 2]  # Limit number of search engines

    async def _handle_crawl_urls(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle URL crawling commands"""
        urls = parameters.get('urls', [])
        respect_robots = parameters.get('respect_robots', False)
        concurrency = parameters.get('concurrency', 3)
        
        if not urls:
            raise ValueError("URLs are required for crawling")
        
        # Validate URLs
        valid_urls = []
        for url in urls:
            try:
                parsed = urlparse(url)
                if parsed.scheme in ('http', 'https') and parsed.netloc:
                    valid_urls.append(url)
            except Exception:
                logger.warning(f"Invalid URL skipped: {url}")
        
        if not valid_urls:
            raise ValueError("No valid URLs provided")
        
        # Create a crawling bot
        from .bot_manager import BotType
        
        bot_id = self.bot_manager.create_bot(
            name=f"Crawler_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            description=f"Crawling {len(valid_urls)} URLs",
            bot_type=BotType.CRAWLER,
            target_urls=valid_urls,
            concurrency=concurrency,
            respect_robots_txt=respect_robots
        )
        
        # Start the crawling bot
        success = await self.bot_manager.start_bot(bot_id)
        
        return {
            'bot_id': bot_id,
            'urls': valid_urls,
            'started': success,
            'status': f'Bot de crawling iniciado para {len(valid_urls)} URLs' if success else 'Error al iniciar crawler'
        }

    async def _handle_create_bot(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle bot creation commands"""
        bot_id = parameters.get('bot_id', '')
        description = parameters.get('description', '')
        bot_type = parameters.get('type', 'scraper')
        config = parameters.get('config', {})
        
        if not description:
            raise ValueError("Bot description is required")
        
        # Create bot using smart description parsing
        actual_bot_id = self.bot_manager.create_smart_bot_from_description(description)
        
        # Apply any additional configuration
        if actual_bot_id in self.bot_manager.active_bots:
            bot = self.bot_manager.active_bots[actual_bot_id]
            
            # Update with provided config
            for key, value in config.items():
                if hasattr(bot.config, key):
                    setattr(bot.config, key, value)
            
            # Auto-start if requested
            if config.get('auto_start', False):
                await self.bot_manager.start_bot(actual_bot_id)
        
        return {
            'bot_id': actual_bot_id,
            'description': description,
            'type': bot_type,
            'status': 'Bot creado exitosamente'
        }

    async def _handle_analyze_data(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle data analysis commands"""
        target = parameters.get('target', '')
        analysis_type = parameters.get('analysis_type', 'basic')
        
        # Get recent data from database
        recent_results = self.db_manager.get_recent_results(limit=100)
        
        if not recent_results:
            return {
                'status': 'No hay datos para analizar',
                'results_count': 0
            }
        
        # Perform basic analysis
        analysis = {
            'total_results': len(recent_results),
            'successful_scrapes': len([r for r in recent_results if r.status == 'SUCCESS']),
            'failed_scrapes': len([r for r in recent_results if r.status == 'FAILED']),
            'domains_scraped': len(set(urlparse(r.url).netloc for r in recent_results)),
            'content_types': {},
            'avg_content_length': 0
        }
        
        # Calculate content statistics
        total_length = 0
        for result in recent_results:
            if result.content_text:
                total_length += len(result.content_text)
            
            content_type = result.content_type or 'unknown'
            analysis['content_types'][content_type] = analysis['content_types'].get(content_type, 0) + 1
        
        if recent_results:
            analysis['avg_content_length'] = total_length / len(recent_results)
        
        # Advanced analysis with LLM if available
        insights = []
        if self.llm_extractor and analysis_type == 'comprehensive':
            try:
                # Summarize trends and patterns
                sample_content = '\n'.join([
                    r.content_text[:200] for r in recent_results[:5] 
                    if r.content_text
                ])
                
                if sample_content:
                    summary = await self.llm_extractor.summarize_content(
                        sample_content, 
                        max_words=150
                    )
                    if summary:
                        insights.append(f"Resumen del contenido: {summary}")
                        
            except Exception as e:
                logger.warning(f"LLM analysis failed: {e}")
                insights.append("Análisis LLM no disponible")
        
        analysis['insights'] = insights
        
        return {
            'status': 'Análisis completado',
            'analysis': analysis,
            'target': target
        }

    async def _handle_get_system_status(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle system status requests"""
        # Get bot statuses
        bots = self.bot_manager.list_bots()
        
        # Get database statistics
        try:
            total_records = len(self.db_manager.get_recent_results(limit=10000))
            recent_records = len(self.db_manager.get_recent_results(limit=100))
        except Exception:
            total_records = 0
            recent_records = 0
        
        # Calculate system health
        active_bots = len([b for b in bots if b['status'] == 'running'])
        error_bots = len([b for b in bots if b['status'] == 'error'])
        
        health_score = 100
        if active_bots == 0 and len(bots) > 0:
            health_score -= 30
        if error_bots > 0:
            health_score -= (error_bots * 20)
        
        health_score = max(0, min(100, health_score))
        
        status = {
            'timestamp': datetime.now().isoformat(),
            'health_score': health_score,
            'system_status': 'healthy' if health_score > 70 else 'degraded' if health_score > 30 else 'critical',
            'bots': {
                'total': len(bots),
                'running': active_bots,
                'stopped': len([b for b in bots if b['status'] == 'stopped']),
                'error': error_bots
            },
            'database': {
                'total_records': total_records,
                'recent_records': recent_records
            },
            'features': {
                'llm_enabled': self.llm_extractor is not None,
                'offline_mode': settings.OFFLINE_MODE,
                'robots_enabled': settings.ROBOTS_ENABLED
            }
        }
        
        return status

    async def _handle_start_bot(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle bot start commands"""
        bot_id = parameters.get('bot_id', '')
        
        if not bot_id:
            raise ValueError("Bot ID is required")
        
        success = await self.bot_manager.start_bot(bot_id)
        
        return {
            'bot_id': bot_id,
            'started': success,
            'status': 'Bot iniciado' if success else 'Error al iniciar bot'
        }

    async def _handle_stop_bot(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle bot stop commands"""
        bot_id = parameters.get('bot_id', '')
        
        if not bot_id:
            raise ValueError("Bot ID is required")
        
        success = await self.bot_manager.stop_bot(bot_id)
        
        return {
            'bot_id': bot_id,
            'stopped': success,
            'status': 'Bot detenido' if success else 'Error al detener bot'
        }

    async def _handle_list_bots(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle list bots commands"""
        bots = self.bot_manager.list_bots()
        
        return {
            'bots': bots,
            'total': len(bots),
            'status': f'Encontrados {len(bots)} bots'
        }

    async def _handle_export_data(
        self, 
        parameters: Dict[str, Any], 
        command_id: str
    ) -> Dict[str, Any]:
        """Handle data export commands"""
        format_type = parameters.get('format', 'json')
        bot_id = parameters.get('bot_id')
        
        if bot_id:
            # Export specific bot data
            filepath = await self.bot_manager.export_bot_data(bot_id, format_type)
            return {
                'bot_id': bot_id,
                'format': format_type,
                'filepath': filepath,
                'status': 'Datos exportados' if filepath else 'Error en exportación'
            }
        else:
            # Export main database
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"scraper_export_{timestamp}.{format_type}"
            
            try:
                if format_type == 'csv':
                    self.db_manager.export_to_csv(filename)
                elif format_type == 'json':
                    self.db_manager.export_to_json(filename)
                else:
                    raise ValueError(f"Unsupported format: {format_type}")
                
                return {
                    'format': format_type,
                    'filepath': filename,
                    'status': 'Datos exportados exitosamente'
                }
                
            except Exception as e:
                raise ValueError(f"Export failed: {str(e)}")

    def get_active_operations(self) -> Dict[str, Any]:
        """Get information about active operations"""
        return {
            'active_commands': list(self.active_operations.keys()),
            'running_bots': [
                bot['id'] for bot in self.bot_manager.list_bots() 
                if bot['status'] == 'running'
            ]
        }

    async def cancel_operation(self, operation_id: str) -> bool:
        """Cancel an active operation"""
        if operation_id in self.active_operations:
            task = self.active_operations[operation_id]
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
            del self.active_operations[operation_id]
            return True
        
        # Try to stop bot if operation_id looks like a bot_id
        if operation_id in self.bot_manager.active_bots:
            return await self.bot_manager.stop_bot(operation_id)
        
        return False